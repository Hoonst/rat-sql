{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정의된 Relation의 개수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ratsql.utils import registry\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def read_json(file):\n",
    "    with open(file) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "def read_jsonl(file):\n",
    "    with open(file) as json_file:\n",
    "        json_data = [json.loads(line) for line in json_file]\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spider_data_loc = 'rat-sql/data/spider/train_spider.json'\n",
    "\n",
    "train_spider = read_json(spider_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spider_data_loc = 'rat-sql/data/spider/nl2code,output_from=true,fs=2,emb=bert,cvlink/enc/train.jsonl'\n",
    "\n",
    "spider_train = read_jsonl(spider_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spider_data_loc = 'rat-sql/data/spider/nl2code,output_from=true,fs=2,emb=bert,cvlink/enc/train.jsonl'\n",
    "\n",
    "spider_train = read_jsonl(spider_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_question', 'question', 'db_id', 'sc_link', 'cv_link', 'columns', 'tables', 'table_bounds', 'column_to_table', 'table_to_columns', 'foreign_keys', 'foreign_keys_tables', 'primary_keys'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = {'1':0, '2': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_question': 'How many heads of the departments are older than 56 ?',\n",
       " 'question': ['how',\n",
       "  'many',\n",
       "  'heads',\n",
       "  'of',\n",
       "  'the',\n",
       "  'departments',\n",
       "  'are',\n",
       "  'older',\n",
       "  'than',\n",
       "  '56',\n",
       "  '?'],\n",
       " 'db_id': 'department_management',\n",
       " 'sc_link': {'q_col_match': {'2,7': 'CPM',\n",
       "   '2,12': 'CPM',\n",
       "   '5,1': 'CPM',\n",
       "   '5,11': 'CPM'},\n",
       "  'q_tab_match': {'2,1': 'TEM', '5,0': 'TEM'}},\n",
       " 'cv_link': {'num_date_match': {'9,1': 'NUMBER',\n",
       "   '9,4': 'NUMBER',\n",
       "   '9,5': 'NUMBER',\n",
       "   '9,6': 'NUMBER',\n",
       "   '9,7': 'NUMBER',\n",
       "   '9,10': 'NUMBER',\n",
       "   '9,11': 'NUMBER',\n",
       "   '9,12': 'NUMBER'},\n",
       "  'cell_match': {},\n",
       "  'value_match': {},\n",
       "  'value_word': {}},\n",
       " 'columns': [['*', '<type: text>'],\n",
       "  ['department', 'id', '<type: number>'],\n",
       "  ['name', '<type: text>'],\n",
       "  ['creation', '<type: text>'],\n",
       "  ['ranking', '<type: number>'],\n",
       "  ['budget', 'in', 'billions', '<type: number>'],\n",
       "  ['nu', '##m', 'employees', '<type: number>'],\n",
       "  ['head', 'id', '<type: number>'],\n",
       "  ['name', '<type: text>'],\n",
       "  ['born', 'state', '<type: text>'],\n",
       "  ['age', '<type: number>'],\n",
       "  ['department', 'id', '<type: number>'],\n",
       "  ['head', 'id', '<type: number>'],\n",
       "  ['temporary', 'acting', '<type: text>']],\n",
       " 'tables': [['department'], ['head'], ['management']],\n",
       " 'table_bounds': [1, 7, 11, 14],\n",
       " 'column_to_table': {'0': None,\n",
       "  '1': 0,\n",
       "  '2': 0,\n",
       "  '3': 0,\n",
       "  '4': 0,\n",
       "  '5': 0,\n",
       "  '6': 0,\n",
       "  '7': 1,\n",
       "  '8': 1,\n",
       "  '9': 1,\n",
       "  '10': 1,\n",
       "  '11': 2,\n",
       "  '12': 2,\n",
       "  '13': 2},\n",
       " 'table_to_columns': {'0': [1, 2, 3, 4, 5, 6],\n",
       "  '1': [7, 8, 9, 10],\n",
       "  '2': [11, 12, 13]},\n",
       " 'foreign_keys': {'11': 1, '12': 7},\n",
       " 'foreign_keys_tables': {'2': [0, 1]},\n",
       " 'primary_keys': [1, 7, 11]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NUMBER': 32758,\n",
       " 'TIME': 3101,\n",
       " 'CELL_MATCH': 7248,\n",
       " 'CPM': 38754,\n",
       " 'CEM': 18136,\n",
       " 'TPM': 4248,\n",
       " 'TEM': 11678,\n",
       " 'PRIMARY': 49412,\n",
       " 'FOREIGN': 52246}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_relation = {}\n",
    "target_relations = ['sc_link', 'cv_link', 'q_col_match', 'q_tab_match', 'num_date_match', 'cell_match', 'foreign_keys', 'primary_keys', ]\n",
    "\n",
    "target_relations = ['NUMBER', 'TIME', 'CELL_MATCH', 'CPM', 'CEM', 'TPM', 'TEM', 'PRIMARY', 'FOREIGN']\n",
    "for t in target_relations:\n",
    "    target_relation[t] = 0\n",
    "for example in spider_train:\n",
    "    sc_link = example['sc_link']\n",
    "    cv_link = example['cv_link']\n",
    "\n",
    "    foreign_keys = len(example['foreign_keys'])\n",
    "    foreign_keys_tables = example['foreign_keys_tables']\n",
    "    primary_keys = len(example['primary_keys'])\n",
    "\n",
    "    q_col_match = sc_link['q_col_match']\n",
    "    q_tab_match = sc_link['q_tab_match']\n",
    "\n",
    "    num_date_match = cv_link['num_date_match']\n",
    "    cell_match = cv_link['cell_match']\n",
    "\n",
    "    number = len([i for i in num_date_match.values() if i == 'NUMBER'])\n",
    "    time = len([j for j in num_date_match.values() if j == 'TIME'])\n",
    "    cell_match = len([j for j in cell_match.values() if j == 'CELLMATCH'])\n",
    "\n",
    "    CPM = len([i for i in q_col_match.values() if i == 'CPM'])\n",
    "    CEM = len([i for i in q_col_match.values() if i == 'CEM'])\n",
    "    \n",
    "    TPM = len([i for i in q_tab_match.values() if i == 'TPM'])\n",
    "    TEM = len([i for i in q_tab_match.values() if i == 'TEM'])\n",
    "\n",
    "    target_relation['CPM'] += CPM\n",
    "    target_relation['CEM'] += CEM\n",
    "    target_relation['TPM'] += TPM\n",
    "    target_relation['TEM'] += TEM\n",
    "    target_relation['NUMBER'] += number\n",
    "    target_relation['TIME'] += time\n",
    "    target_relation['CELL_MATCH'] += cell_match\n",
    "    target_relation['PRIMARY'] += primary_keys\n",
    "    target_relation['FOREIGN'] += foreign_keys\n",
    "\n",
    "target_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n",
      "WARNING <class 'ratsql.models.enc_dec.EncDecModel'>: superfluous {'decoder_preproc': {'grammar': {'clause_order': None, 'end_with_from': True, 'factorize_sketch': 2, 'include_literals': False, 'infer_from_conditions': True, 'name': 'spider', 'output_from': True, 'use_table_pointer': True}, 'save_path': 'rat-sql/data/spider/nl2code,output_from=true,fs=2,emb=bert,cvlink', 'use_seq_elem_rules': True}, 'encoder_preproc': {'bert_version': 'bert-large-uncased-whole-word-masking', 'compute_cv_link': True, 'compute_sc_link': True, 'db_path': 'rat-sql/data/spider/database', 'fix_issue_16_primary_keys': True, 'include_table_name_in_column': False, 'save_path': 'rat-sql/data/spider/nl2code,output_from=true,fs=2,emb=bert,cvlink'}}\n",
      "WARNING <class 'ratsql.models.spider.spider_enc.SpiderEncoderBert'>: superfluous {'enc_qv_link': False, 'qv_link': False, 'use_orthogonal': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Relations: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from rat-sql/logdir/bert_run/bs=6,qv_link=false,dist=true,orthog=false,orth_init=false,bi_way=true,bi_match=true/model_checkpoint-00060500\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.59 GiB total capacity; 9.01 GiB already allocated; 11.19 MiB free; 9.02 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80451/530209740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mrelation_k_emb_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder.encs_update.encoder.layers.0.relation_k_emb.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repo/rat-sql/ratsql/commands/infer.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, logdir, step)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 2. Restore its parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repo/rat-sql/ratsql/utils/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, model_dir, map_location, step, item_keys)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         last_step = load_checkpoint(\n\u001b[0;32m--> 129\u001b[0;31m             items2restore, model_dir, map_location, step)\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repo/rat-sql/ratsql/utils/saver.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(item_dict, model_dir, map_location, step)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading model from %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mold_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.59 GiB total capacity; 9.01 GiB already allocated; 11.19 MiB free; 9.02 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from pyvis.network import Network\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import scipy\n",
    "import sys\n",
    "sys.path.append('rat-sql')\n",
    "sys.path.append('../')\n",
    "\n",
    "import attr\n",
    "import _jsonnet\n",
    "import json \n",
    "\n",
    "from ratsql.commands.infer import Inferer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "\n",
    "os.chdir('/repo')\n",
    "\n",
    "@attr.s\n",
    "class InferConfig:\n",
    "    config = attr.ib()\n",
    "    config_args = attr.ib()\n",
    "    logdir = attr.ib()\n",
    "    section = attr.ib()\n",
    "    beam_size = attr.ib()\n",
    "    output = attr.ib()\n",
    "    step = attr.ib()\n",
    "    use_heuristic = attr.ib(default=False)\n",
    "    mode = attr.ib(default=\"infer\")\n",
    "    limit = attr.ib(default=None)\n",
    "    output_history = attr.ib(default=False)\n",
    "\n",
    "bs=\"6\"\n",
    "qv_link=\"false\"\n",
    "dist_relation=\"true\"\n",
    "orthog=\"false\"\n",
    "orth_init=\"false\"\n",
    "bi_match=\"true\"\n",
    "bi_way=\"true\"\n",
    "\n",
    "infer_config = InferConfig(config='rat-sql/configs/spider/nl2code-bert.jsonnet', \n",
    "                            config_args='{\"att\": 1, \"bert_lr\": 3e-06, \"bert_token_type\": true, \"bert_version\": \"bert-large-uncased-whole-word-masking\", \"bs\": 6, \"clause_order\": null, \"cv_link\": true, \"data_path\": \"rat-sql/data/spider/\", \"decoder_hidden_size\": 512, \"end_lr\": 0, \"end_with_from\": true, \"loss\": \"label_smooth\", \"lr\": 0.000744, \"max_steps\": 121000, \"num_batch_accumulated\": 4, \"num_layers\": 8, \"qv_link\": '+qv_link+ ', \"dist_relation\": ' + dist_relation + ', \"use_orthogonal\": ' + orthog + ', \"use_orth_init\": '+orth_init+', \"sc_link\": true, \"summarize_header\": \"avg\", \"use_align_loss\": true, \"use_align_mat\": true, \"use_column_type\": false, \"bi_match\": '+bi_match+', \"bi_way\": '+bi_way+'}', \n",
    "                            logdir='rat-sql/logdir/bert_run', \n",
    "                            section='val',\n",
    "                            beam_size=1, \n",
    "                            output='__LOGDIR__/ie_dirs/bert_run_true_1-step1.infer', \n",
    "                            step=1, use_heuristic=True, mode='infer', limit=None, output_history=False)\n",
    "\n",
    "config = json.loads(_jsonnet.evaluate_file(infer_config.config, tla_codes={'args': infer_config.config_args}))\n",
    "\n",
    "inferer = Inferer(config)\n",
    "\n",
    "logdir = os.path.join(infer_config.logdir, config['model_name'])\n",
    "step = 60500\n",
    "\n",
    "model = inferer.load_model(logdir, step)\n",
    "\n",
    "relation_k_emb_0 = model.state_dict()['encoder.encs_update.encoder.layers.0.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_1 = model.state_dict()['encoder.encs_update.encoder.layers.1.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_2 = model.state_dict()['encoder.encs_update.encoder.layers.2.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_3 = model.state_dict()['encoder.encs_update.encoder.layers.3.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_4 = model.state_dict()['encoder.encs_update.encoder.layers.4.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_5 = model.state_dict()['encoder.encs_update.encoder.layers.5.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_6 = model.state_dict()['encoder.encs_update.encoder.layers.6.relation_k_emb.weight'].cpu()\n",
    "relation_k_emb_7 = model.state_dict()['encoder.encs_update.encoder.layers.7.relation_k_emb.weight'].cpu()\n",
    "\n",
    "relation_ks = [relation_k_emb_0, relation_k_emb_1, relation_k_emb_2, relation_k_emb_3, relation_k_emb_4, relation_k_emb_5, relation_k_emb_6, relation_k_emb_7]\n",
    "\n",
    "relation_v_emb_0 = model.state_dict()['encoder.encs_update.encoder.layers.0.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_1 = model.state_dict()['encoder.encs_update.encoder.layers.1.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_2 = model.state_dict()['encoder.encs_update.encoder.layers.2.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_3 = model.state_dict()['encoder.encs_update.encoder.layers.3.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_4 = model.state_dict()['encoder.encs_update.encoder.layers.4.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_5 = model.state_dict()['encoder.encs_update.encoder.layers.5.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_6 = model.state_dict()['encoder.encs_update.encoder.layers.6.relation_v_emb.weight'].cpu()\n",
    "relation_v_emb_7 = model.state_dict()['encoder.encs_update.encoder.layers.7.relation_v_emb.weight'].cpu()\n",
    "\n",
    "relation_vs = [relation_v_emb_0, relation_v_emb_1, relation_v_emb_2, relation_v_emb_3, relation_v_emb_4, relation_v_emb_5, relation_v_emb_6, relation_v_emb_7]\n",
    "\n",
    "relation_index = {('qq_dist', -2): 0,\n",
    "                    ('qq_dist', -1): 1,\n",
    "                    ('qq_dist', 0): 2,\n",
    "                    ('qq_dist', 1): 3,\n",
    "                    ('qq_dist', 2): 4,\n",
    "                    'qc_default': 5,\n",
    "                    'qt_default': 6,\n",
    "                    'cq_default': 7,\n",
    "                    'cc_default': 8,\n",
    "                    'cc_foreign_key_forward': 9,\n",
    "                    'cc_foreign_key_backward': 10,\n",
    "                    'cc_table_match': 11,\n",
    "                    ('cc_dist', -2): 12,\n",
    "                    ('cc_dist', -1): 13,\n",
    "                    ('cc_dist', 0): 14,\n",
    "                    ('cc_dist', 1): 15,\n",
    "                    ('cc_dist', 2): 16,\n",
    "                    'ct_default': 17,\n",
    "                    'ct_foreign_key': 18,\n",
    "                    'ct_primary_key': 19,\n",
    "                    'ct_table_match': 20,\n",
    "                    'ct_any_table': 21,\n",
    "                    'tq_default': 22,\n",
    "                    'tc_default': 23,\n",
    "                    'tc_primary_key': 24,\n",
    "                    'tc_table_match': 25,\n",
    "                    'tc_any_table': 26,\n",
    "                    'tc_foreign_key': 27,\n",
    "                    'tt_default': 28,\n",
    "                    'tt_foreign_key_forward': 29,\n",
    "                    'tt_foreign_key_backward': 30,\n",
    "                    'tt_foreign_key_both': 31,\n",
    "                    ('tt_dist', -2): 32,\n",
    "                    ('tt_dist', -1): 33,\n",
    "                    ('tt_dist', 0): 34,\n",
    "                    ('tt_dist', 1): 35,\n",
    "                    ('tt_dist', 2): 36,\n",
    "                    'qcCEM': 37,\n",
    "                    'cqCEM': 38,\n",
    "                    'qtTEM': 39,\n",
    "                    'tqTEM': 40,\n",
    "                    'qcCPM': 41,\n",
    "                    'cqCPM': 42,\n",
    "                    'qtTPM': 43,\n",
    "                    'tqTPM': 44,\n",
    "                    'qcNUMBER': 45,\n",
    "                    'cqNUMBER': 46,\n",
    "                    'qcTIME': 47,\n",
    "                    'cqTIME': 48,\n",
    "                    'qcCELLMATCH': 49,\n",
    "                    'cqCELLMATCH': 50}\n",
    "\n",
    "relation_index_list = list(relation_index.keys())\n",
    "\n",
    "print(f'bs: {bs}, qv_link: {qv_link}, dist_relation: {dist_relation}, orthog: {orthog}, orth_init: {orth_init}, bi_match: {bi_match}, bi_way: {bi_way}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model_preproc = registry.instantiate(\n",
    "                registry.lookup('model', config['model']).Preproc,\n",
    "                config['model'],\n",
    "                unused_keys=('name',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ratsql.models.enc_dec.EncDecModel.Preproc at 0x7f90361853d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_data = model_preproc.dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "desc = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_date_match': {'9,1': 'NUMBER',\n",
       "  '9,4': 'NUMBER',\n",
       "  '9,5': 'NUMBER',\n",
       "  '9,6': 'NUMBER',\n",
       "  '9,7': 'NUMBER',\n",
       "  '9,10': 'NUMBER',\n",
       "  '9,11': 'NUMBER',\n",
       "  '9,12': 'NUMBER'},\n",
       " 'cell_match': {},\n",
       " 'value_match': {},\n",
       " 'value_word': {}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[0].get('cv_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('qq_dist', -2): 0,\n",
       " ('qq_dist', -1): 1,\n",
       " ('qq_dist', 0): 2,\n",
       " ('qq_dist', 1): 3,\n",
       " ('qq_dist', 2): 4,\n",
       " 'qc_default': 5,\n",
       " 'qt_default': 6,\n",
       " 'cq_default': 7,\n",
       " 'cc_default': 8,\n",
       " 'cc_foreign_key_forward': 9,\n",
       " 'cc_foreign_key_backward': 10,\n",
       " 'cc_table_match': 11,\n",
       " ('cc_dist', -2): 12,\n",
       " ('cc_dist', -1): 13,\n",
       " ('cc_dist', 0): 14,\n",
       " ('cc_dist', 1): 15,\n",
       " ('cc_dist', 2): 16,\n",
       " 'ct_default': 17,\n",
       " 'ct_foreign_key': 18,\n",
       " 'ct_primary_key': 19,\n",
       " 'ct_table_match': 20,\n",
       " 'ct_any_table': 21,\n",
       " 'tq_default': 22,\n",
       " 'tc_default': 23,\n",
       " 'tc_primary_key': 24,\n",
       " 'tc_table_match': 25,\n",
       " 'tc_any_table': 26,\n",
       " 'tc_foreign_key': 27,\n",
       " 'tt_default': 28,\n",
       " 'tt_foreign_key_forward': 29,\n",
       " 'tt_foreign_key_backward': 30,\n",
       " 'tt_foreign_key_both': 31,\n",
       " ('tt_dist', -2): 32,\n",
       " ('tt_dist', -1): 33,\n",
       " ('tt_dist', 0): 34,\n",
       " ('tt_dist', 1): 35,\n",
       " ('tt_dist', 2): 36,\n",
       " 'qcCEM': 37,\n",
       " 'cqCEM': 38,\n",
       " 'qtTEM': 39,\n",
       " 'tqTEM': 40,\n",
       " 'qcCPM': 41,\n",
       " 'cqCPM': 42,\n",
       " 'qtTPM': 43,\n",
       " 'tqTPM': 44,\n",
       " 'qcNUMBER': 45,\n",
       " 'cqNUMBER': 46,\n",
       " 'qcTIME': 47,\n",
       " 'cqTIME': 48,\n",
       " 'qcCELLMATCH': 49,\n",
       " 'cqCELLMATCH': 50}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_data_loader = torch.utils.data.DataLoader(\n",
    "            train_data,\n",
    "            batch_size=self.train_config.eval_batch_size,\n",
    "            collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.encoder.encs_update.compute_relations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
